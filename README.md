### UniMachineLearning
```markdown
### Лабораторная работа №1: Классификация  
**Дисциплина:** Машинное обучение  
**Тема:** Классификация  

## Описание  
В данной лабораторной работе проводится анализ и сравнение эффективности трех алгоритмов классификации:  
- Метод K ближайших соседей (k-Nearest Neighbors, KNN)  
- Метод опорных векторов (Support Vector Machine, SVM)  
- Модель случайного леса (Random Forest)  

Работа включает в себя следующие этапы:  
1. **Теоретическое введение** — описание используемых алгоритмов.  
2. **Предобработка данных** — заполнение пропусков, удаление ненужных переменных, стандартизация и кодирование категориальных данных.  
3. **Обучение и тестирование моделей** — настройка гиперпараметров, обучение моделей и их оценка на тестовых данных.  
4. **Анализ результатов** — визуализация ROC-AUC кривых, оценка метрик качества и важности признаков.

## Используемые технологии  
- Python  
- Библиотеки:  
  - `sklearn` (KNeighborsClassifier, SVC, RandomForestClassifier, RandomizedSearchCV, GridSearchCV)  
  - `pandas` и `numpy` для работы с данными  
  - `matplotlib` и `seaborn` для визуализации  

## Предобработка данных  
Перед обучением моделей выполняется:  
- Заполнение пропусков.  
- Удаление выбросов с использованием диаграмм рассеяния и ящиков с усами.  
- Кодирование категориальных переменных с помощью `OneHotEncoding`.  
- Стандартизация числовых данных с использованием `SimpleScaler`.  

## Модели и результаты  
### KNN (Метод K ближайших соседей)  
- Настройка гиперпараметров через `RandomizedSearchCV`.  
- Оценка по метрикам: Precision, Recall, F1-score, ROC-AUC.  
- Визуализация ROC-AUC кривых для тестовой и валидационной выборок.  

### SVM (Метод опорных векторов)  
- Подбор гиперпараметров с использованием `GridSearchCV`.  
- Построение ROC-AUC кривых и анализ производительности.  

### Random Forest (Случайный лес)  
- Настройка гиперпараметров через `RandomizedSearchCV`.  
- Построение графика feature importance.  

## Визуализация  
Для каждого этапа анализа представлены:  
- Гистограммы, матрицы корреляций и диаграммы рассеяния для исследования данных.  
- ROC-AUC кривые для оценки моделей.  
- График важности признаков (`Feature Importance`) для модели случайного леса.  

## Выводы  
Проведён сравнительный анализ эффективности алгоритмов классификации на одном наборе данных.  
- **Все модели продемонстрировали высокую точность и стабильные значения метрик качества.**  
- Наибольшую точность классификации показала модель случайного леса, что подтверждается её высокой метрикой ROC-AUC и визуализацией важности признаков.  

## Запуск  
1. Установите необходимые библиотеки:  
   ```bash
   pip install -r requirements.txt
    
2. Запустите Jupyter Notebook или Python-скрипт с реализацией анализа.  

## Файлы проекта  
- `data/` — Папка с набором данных.  
- `notebooks/` — Jupyter Notebook с кодом выполнения лабораторной работы.  
- `results/` — Графики и отчёты о выполнении работы.  


### Лабораторная работа №2: Кластеризация

## Описание проекта
Данный проект реализует и сравнивает три подхода к кластеризации данных:
1. **K-Means**
2. **Иерархическая кластеризация**
3. **DBSCAN**

Кластеризация используется для выявления скрытых структур в данных, их сегментации, снижения размерности и визуализации.

## Содержание проекта
- **Теория**: Обзор основных методов кластеризации и их метрик.
- **Предобработка данных**: Очищение, нормализация и разделение данных.
- **Модель K-Means**: Выбор оптимального числа кластеров методом "локтя", расчет метрик (DBI, S).
- **Иерархическая кластеризация**: Построение дендрограммы, анализ и расчет метрик.
- **Модель DBSCAN**: Обнаружение кластеров произвольной формы, подбор параметров (ε, minPts).

## Требования
Для запуска проекта потребуется:
- Python 3.9+
- Установленные библиотеки:
  - pandas
  - numpy
  - matplotlib
  - seaborn
  - scikit-learn

Установить зависимости можно с помощью команды:
```bash
pip install -r requirements.txt


## Структура репозитория
- `data/`: Данные для кластеризации.
- `src/`: Реализация методов предобработки данных и кластеризации.
- `notebooks/`: Jupyter Notebook с результатами анализа.
- `README.md`: Описание проекта.
- `requirements.txt`: Зависимости проекта.

## Предобработка данных
Перед применением методов кластеризации:
1. **Удалены неинформативные столбцы.**
2. **Оставлены значимые признаки**:
   - Осадки
   - Использование удобрений
   - Использование орошения
   - Урожайность
3. **Нормализованы данные** с помощью стандартизации.
4. **Разделены наборы данных**:
   - Тренировочный
   - Валидационный
   - Тестовый

## Метрики оценки
Для оценки качества кластеризации использовались:
- **Силуэт (Silhouette)**: Насколько кластеры разделены.
- **Коэффициент Дэвиса–Боллдина (DBI)**: Компактность и разделимость кластеров.

## Результаты
### K-Means
- Оптимальное число кластеров: 8 (метод "локтя").
- Метрики:
  - DBI = 0.58
  - S = 0.55

### Иерархическая кластеризация
- Оптимальное число кластеров: 8 (по дендрограмме).
- Метрики:
  - DBI = 0.87
  - S = 0.46

### DBSCAN
- Подбор параметров показал высокую чувствительность алгоритма.
- Метрики:
  - DBI = 1.07
  - S = 0.42

## Вывод
Методы **K-Means** и **Иерархической кластеризации** оказались наиболее подходящими для анализа. DBSCAN показал ограниченные результаты из-за чувствительности к параметрам и сложности обработки данных с размытыми границами кластеров.

### Отчет по лабораторной работе №3  
### Дисциплина: Машинное обучение  
### Тема: Регрессия  

## Описание  
Целью данной лабораторной работы является закрепление навыков предобработки данных, а также применение методов машинного обучения для решения задач регрессии.  

В рамках работы рассматриваются три модели:  
- Линейная регрессия (Linear Regression)  
- LASSO-регрессия  
- Ridge-регрессия  

## Цели и задачи  
### Цель  
Научиться применять методы регрессии для прогнозирования на основе реальных данных.  

### Задачи  
1. Провести предварительную обработку данных:  
   - Визуализация значимых признаков;  
   - Очистка данных (удаление пропусков, нормализация, удаление дубликатов).  
2. Обучить модели:  
   - Linear Regression;  
   - LASSO (L1-регуляризация);  
   - Ridge (L2-регуляризация).  
3. Оценить качество моделей:  
   - Использовать метрику MSE (среднеквадратическая ошибка);  
   - Построить графики для анализа результатов.  

## Используемые метрики  
**MSE (Mean Squared Error):**  
Метрика оценивает среднюю квадратичную разницу между реальными и предсказанными значениями. Чем ниже MSE, тем лучше модель.  

## Этапы работы  
1. **Предобработка данных:**  
   Визуализация данных, нормализация и очистка.  

2. **Инициализация моделей:**  
   Использованы классы `LinearRegression`, `Lasso` и `Ridge` из библиотеки `sklearn`.  

3. **Обучение моделей:**  
   Каждая модель обучалась на данных `x_train` и `y_train` с использованием метода `.fit()`.  

4. **Оценка качества моделей:**  
   Для каждой модели рассчитывались значения метрик на обучающем и тестовом наборах данных.  

5. **Хранение результатов:**  
   Результаты сохранены в словарь `results` для последующего анализа.  

## Анализ результатов  
1. **Linear Regression:**  
   - MSE на обучающих данных: 0.0376  
   - MSE на тестовых данных: 0.0373  
   Линейная регрессия показала высокую точность и хорошую обобщающую способность.  

2. **LASSO:**  
   - Значительно более высокое MSE, что говорит о чрезмерной регуляризации.  
   - Модель плохо справилась с прогнозированием.  

3. **Ridge:**  
   - Результаты аналогичны линейной регрессии.  
   - Модель продемонстрировала надежность при умеренной регуляризации.  

## Вывод  
Модель линейной регрессии показала лучшие результаты среди рассмотренных моделей. Ridge-регрессия продемонстрировала схожие показатели, что подтверждает ее применимость в данной задаче. Модель LASSO оказалась неэффективной из-за чрезмерного регуляризирующего эффекта.  

## Используемые библиотеки  
- `numpy`  
- `pandas`  
- `matplotlib`  
- `sklearn`  

## Инструкция по запуску  
1. Установите все необходимые зависимости:  
   ```bash
   pip install numpy pandas matplotlib scikit-learn
   
2. Запустите скрипт обучения и анализа моделей:  
   ```bash
   python regression_analysis.py
   
3. Результаты будут сохранены в словарь и выведены в консоль.  
```
