### UniMachineLearning
```markdown
### Лабораторная работа №1: Классификация  
**Дисциплина:** Машинное обучение  
**Тема:** Классификация  

## Описание  
В данной лабораторной работе проводится анализ и сравнение эффективности трех алгоритмов классификации:  
- Метод K ближайших соседей (k-Nearest Neighbors, KNN)  
- Метод опорных векторов (Support Vector Machine, SVM)  
- Модель случайного леса (Random Forest)  

Работа включает в себя следующие этапы:  
1. **Теоретическое введение** — описание используемых алгоритмов.  
2. **Предобработка данных** — заполнение пропусков, удаление ненужных переменных, стандартизация и кодирование категориальных данных.  
3. **Обучение и тестирование моделей** — настройка гиперпараметров, обучение моделей и их оценка на тестовых данных.  
4. **Анализ результатов** — визуализация ROC-AUC кривых, оценка метрик качества и важности признаков.

## Используемые технологии  
- Python  
- Библиотеки:  
  - `sklearn` (KNeighborsClassifier, SVC, RandomForestClassifier, RandomizedSearchCV, GridSearchCV)  
  - `pandas` и `numpy` для работы с данными  
  - `matplotlib` и `seaborn` для визуализации  

## Предобработка данных  
Перед обучением моделей выполняется:  
- Заполнение пропусков.  
- Удаление выбросов с использованием диаграмм рассеяния и ящиков с усами.  
- Кодирование категориальных переменных с помощью `OneHotEncoding`.  
- Стандартизация числовых данных с использованием `SimpleScaler`.  

## Модели и результаты  
### KNN (Метод K ближайших соседей)  
- Настройка гиперпараметров через `RandomizedSearchCV`.  
- Оценка по метрикам: Precision, Recall, F1-score, ROC-AUC.  
- Визуализация ROC-AUC кривых для тестовой и валидационной выборок.  

### SVM (Метод опорных векторов)  
- Подбор гиперпараметров с использованием `GridSearchCV`.  
- Построение ROC-AUC кривых и анализ производительности.  

### Random Forest (Случайный лес)  
- Настройка гиперпараметров через `RandomizedSearchCV`.  
- Построение графика feature importance.  

## Визуализация  
Для каждого этапа анализа представлены:  
- Гистограммы, матрицы корреляций и диаграммы рассеяния для исследования данных.  
- ROC-AUC кривые для оценки моделей.  
- График важности признаков (`Feature Importance`) для модели случайного леса.  

## Выводы  
Проведён сравнительный анализ эффективности алгоритмов классификации на одном наборе данных.  
- **Все модели продемонстрировали высокую точность и стабильные значения метрик качества.**  
- Наибольшую точность классификации показала модель случайного леса, что подтверждается её высокой метрикой ROC-AUC и визуализацией важности признаков.  

## Запуск  
1. Установите необходимые библиотеки:  
   ```bash
   pip install -r requirements.txt
   ```  
2. Запустите Jupyter Notebook или Python-скрипт с реализацией анализа.  

## Файлы проекта  
- `data/` — Папка с набором данных.  
- `notebooks/` — Jupyter Notebook с кодом выполнения лабораторной работы.  
- `results/` — Графики и отчёты о выполнении работы.  


### Лабораторная работа №2: Кластеризация

## Описание проекта
Данный проект реализует и сравнивает три подхода к кластеризации данных:
1. **K-Means**
2. **Иерархическая кластеризация**
3. **DBSCAN**

Кластеризация используется для выявления скрытых структур в данных, их сегментации, снижения размерности и визуализации.

## Содержание проекта
- **Теория**: Обзор основных методов кластеризации и их метрик.
- **Предобработка данных**: Очищение, нормализация и разделение данных.
- **Модель K-Means**: Выбор оптимального числа кластеров методом "локтя", расчет метрик (DBI, S).
- **Иерархическая кластеризация**: Построение дендрограммы, анализ и расчет метрик.
- **Модель DBSCAN**: Обнаружение кластеров произвольной формы, подбор параметров (ε, minPts).

## Требования
Для запуска проекта потребуется:
- Python 3.9+
- Установленные библиотеки:
  - pandas
  - numpy
  - matplotlib
  - seaborn
  - scikit-learn

Установить зависимости можно с помощью команды:
```bash
pip install -r requirements.txt
```

## Структура репозитория
- `data/`: Данные для кластеризации.
- `src/`: Реализация методов предобработки данных и кластеризации.
- `notebooks/`: Jupyter Notebook с результатами анализа.
- `README.md`: Описание проекта.
- `requirements.txt`: Зависимости проекта.

## Предобработка данных
Перед применением методов кластеризации:
1. **Удалены неинформативные столбцы.**
2. **Оставлены значимые признаки**:
   - Осадки
   - Использование удобрений
   - Использование орошения
   - Урожайность
3. **Нормализованы данные** с помощью стандартизации.
4. **Разделены наборы данных**:
   - Тренировочный
   - Валидационный
   - Тестовый

## Метрики оценки
Для оценки качества кластеризации использовались:
- **Силуэт (Silhouette)**: Насколько кластеры разделены.
- **Коэффициент Дэвиса–Боллдина (DBI)**: Компактность и разделимость кластеров.

## Результаты
### K-Means
- Оптимальное число кластеров: 8 (метод "локтя").
- Метрики:
  - DBI = 0.58
  - S = 0.55

### Иерархическая кластеризация
- Оптимальное число кластеров: 8 (по дендрограмме).
- Метрики:
  - DBI = 0.87
  - S = 0.46

### DBSCAN
- Подбор параметров показал высокую чувствительность алгоритма.
- Метрики:
  - DBI = 1.07
  - S = 0.42

## Вывод
Методы **K-Means** и **Иерархической кластеризации** оказались наиболее подходящими для анализа. DBSCAN показал ограниченные результаты из-за чувствительности к параметрам и сложности обработки данных с размытыми границами кластеров.

## Авторы  
- **Студент:** Попов Н.А.  
```
